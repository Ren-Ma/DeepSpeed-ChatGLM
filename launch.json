{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "KnowLM train",
            "type": "python",
            "request": "launch",
            "program": "/root/anaconda3/envs/unichat/bin/deepspeed",
            "justMyCode": false,
            "console": "internalConsole",
            // "env":{"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
            "env":{"CUDA_VISIBLE_DEVICES": "4"},
            "args": [
                // "--num_gpus=4",
                "${workspaceFolder}/KnowLM/pretrain/train.py",
                "--model_name_or_path", "/data/caihua/huggingfaceModels/llama/llama-13B",
                "--model_max_length", "1024",
                "--data_path", "${workspaceFolder}/law_data/preproc刑法",
                "--output_dir", "${workspaceFolder}/KnowLM/pretrain/output",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "16",
                // "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size", "1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps", "100",
                "--save_total_limit", "1",
                "--learning_rate", "1.5e-5",
                "--warmup_steps", "300",
                "--logging_steps", "1",
                "--report_to", "tensorboard",
                "--gradient_checkpointing", "True",
                "--deepspeed", "${workspaceFolder}/KnowLM/pretrain/configs/config.json",
                "--fp16", "True",
                "--log_on_each_node", "False",
                "--lr_scheduler_type", "cosine",
                "--adam_beta1", "0.9",
                "--adam_beta2", "0.95",
                "--weight_decay", "0.1" 
            ]
        },
        {
            "name": "reward model",
            "type": "python",
            "request": "launch",
            "program": "/root/anaconda3/envs/unichat/bin/deepspeed",
            "justMyCode": false,
            "console": "internalConsole",
            // "env":{"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
            "env":{"CUDA_VISIBLE_DEVICES": "4"},
            "args": [
                // "--num_gpus=4",
                "${workspaceFolder}/DeepSpeedExamples-ChatGLM/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py",
                "--model_name_or_path", "${workspaceFolder}/inference_models/chatglm-6b",
                "--output_dir", "${workspaceFolder}/inference_models/reward0525",
                "--data_path", "${workspaceFolder}/GPT-4-LLM/data/reward_data/unidt_FAQ_reward0525.csv",
                "--data_output_path", "${workspaceFolder}/GPT-4-LLM/data/reward_data/tokenized_data",
                "--data_split","0,8,2",
                "--num_padding_at_beginning=0",
                "--per_device_train_batch_size=1",
                "--per_device_eval_batch_size=16",
                "--max_seq_len=1536",
                // "--max_seq_len=768",
                "--learning_rate=5e-5",
                "--weight_decay=0.1",
                "--num_train_epochs=1",
                "--disable_dropout",
                "--gradient_accumulation_steps=1",
                // "--offload",
                "--lr_scheduler_type", "cosine",
                "--num_warmup_steps=0",
                "--seed=1234",
                "--zero_stage=2",
                "--deepspeed",
                // "--load_from_checkpoint", "True",
                "--model_class=chatglm"
            ]
        },
        {
            "name": "ppo",
            "type": "python",
            "request": "launch",
            "program": "/root/anaconda3/envs/unichat/bin/deepspeed",
            "justMyCode": false,
            "console": "internalConsole",
            // "env":{"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
            "env":{"CUDA_VISIBLE_DEVICES": "4"},
            "args": [
                "--master_port=12345",
                "${workspaceFolder}/DeepSpeedExamples-ChatGLM/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/main.py",
                "--actor_model_name_or_path", "/data/caihua/huggingfaceModels/sft_model_lora_2048_aug0602",
                "--critic_model_name_or_path", "${workspaceFolder}/inference_models/reward0525",
                "--output_dir", "${workspaceFolder}/inference_models/rlhf0602_unichat_round1",
                // "--data_path=${workspaceFolder}/GPT-4-LLM/data/reward_data/unidt_FAQ_reward0525.csv",
                "--data_path=${workspaceFolder}/unichat_num212.xlsx",
                "--data_output_path", "${workspaceFolder}/GPT-4-LLM/data/ppo_data/tokenized_data",
                "--data_split=0,0,10",
                "--num_padding_at_beginning=0",
                "--per_device_train_batch_size=1",
                "--per_device_mini_train_batch_size=1",
                "--generation_batch_numbers=1",
                "--ppo_epochs=1",
                "--max_answer_seq_len=512",
                "--max_prompt_seq_len=512",
                "--actor_learning_rate=9.65e-6",
                "--critic_learning_rate=5e-6",
                "--actor_weight_decay=0.1",
                "--critic_weight_decay=0.1",
                "--num_train_epochs=1",
                "--lr_scheduler_type=cosine",
                "--gradient_accumulation_steps=1",
                "--disable_actor_dropout",
                // "--num_warmup_steps=100",
                "--num_warmup_steps=0",
                "--deepspeed",
                "--seed=1234",
                "--enable_hybrid_engine",
                "--actor_zero_stage=3",
                "--critic_zero_stage=3",
                // "--offload_reference_model",
                "--model_class=chatglm"
            ]
        },
        {
            "name": "ceval",
            "type": "python",
            "request": "launch",
            "program": "/data/renma/unigpt/ceval/code/evaluator_series/eval.py",
            "console": "internalConsole",
            "justMyCode": false,
            // "env":{"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
            "args": [
                "--model_name=chatglm",
                "--few_shot",
                "--ntrain=5",
                "--cuda_device=0",
                "--model_path", "/data/caihua/huggingfaceModels/chatglm-6b-lora-hf-0524",
                // "--cot"
            ]
        },
    ]
}